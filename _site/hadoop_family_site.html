<!DOCTYPE html>
<html>
<head>
    <!--
    * Author:         BeiYuu
    * Revised:        LijunYu
    -->
    <meta charset="utf-8" />
    <title>Hadoop Resource | Lijun Yu's blog</title>
    <meta name="author" content="LijunYu" />
    <meta name="renderer" content="webkit">
    <meta name="description" content="Everything about LijunYu" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0, minimum-scale=1.0">
    <link rel="stylesheet" href="/css/default.css" type="text/css" />
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
    <link rel="alternate" type="application/atom+xml" title="Recent Entries" href="/atom.xml" />
    <link rel="alternatecss" type="application/rss+xml" title="“Lijun Yu's Blog”" href="http://helloourworld.github.io/feed.xml">
    <script src="/js/jquery-1.7.1.min.js" type="text/javascript"></script>
</head>
<body>

    <div class="home-menu">
        <div class="home-icon-con">
            <a class="home-menu-icon" href="/">LijunYu</a>
            <a class="home-follow" href="#" title="Contact Me">+</a>
        </div>
        <div class="home-contact">
            <a href="https://github.com/helloourworld/" target="_blank" style="margin-left:-5px;"><img src="https://github.com/favicon.ico" alt="" width="22"/></a>
            <a href="http://www.douban.com/people/59824156/" target="_blank" style="text-align:center;"><img src="http://www.douban.com/favicon.ico" alt="" width="22"/></a>
            <a href="/feed.xml" target="_blank" style="text-align:right"><img src="http://freefavicons.org/download/rss/rss.ico" alt="" width="22"/></a>
        </div>
    </div>

    <link rel="stylesheet" href="/js/prettify/prettify.css" />
<style type="text/css">
    body { background:#e8e8e8; }
    @media screen and (max-width: 750px){
        body { background:#fff; }
    }
    @media screen and (max-width: 1020px){
        body { background:#fff; }
    }
</style>

<div id="content">
    <div class="entry">
        <h1 class="entry-title"><a href="/hadoop_family_site" title="Hadoop Resource">Hadoop Resource</a></h1>
        <p class="entry-date">2016-08-06</p>
        <h2 id="apache">Apache</h2>

<p><a href="http://hadoop.apache.org/docs/r2.6.4/hadoop-project-dist">Apache docs</a></p>

<h2 id="cloudera">Cloudera</h2>

<p><a href="http://blog.cloudera.com/">Cloudera Engineering Blog</a></p>

<h2 id="hortonworks">hortonworks</h2>

<p><a href="http://zh.hortonworks.com/">hortonworks公司中文网</a></p>

<p><a href="http://zh.hortonworks.com/training/certification/hdpcd-certification/">THE HDPCD EXAM</a></p>

<p><a href="http://ifeve.com/hortonworkshdp-hdpcd/">Hortonworks(HDP)开发者认证</a></p>

<h3 id="section">考试内容列表</h3>

<table>
  <tbody>
    <tr>
      <td>类型</td>
      <td>[任务]</td>
    </tr>
    <tr>
      <td>数据获取</td>
      <td><a href="http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-common/FileSystemShell.html#put">通过Hadoop Shell把本地文件上传到HDFS</a></td>
    </tr>
    <tr>
      <td> </td>
      <td><a href="http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-common/FileSystemShell.html#mkdir">使用Hadoop Shell在HDFS上创建一个新的目录</a></td>
    </tr>
    <tr>
      <td> </td>
      <td><a href="http://sqoop.apache.org/docs/1.4.5/SqoopUserGuide.html#_literal_sqoop_import_literal">从一个关系型数据库中导入数据到HDFS</a></td>
    </tr>
    <tr>
      <td> </td>
      <td><a href="http://sqoop.apache.org/docs/1.4.5/SqoopUserGuide.html#_free_form_query_imports">导入关系型数据的查询结果到HDFS</a></td>
    </tr>
    <tr>
      <td> </td>
      <td><a href="http://sqoop.apache.org/docs/1.4.5/SqoopUserGuide.html#_importing_data_into_hive">从一个关系型数据库中导入数据到一个新的或者已经存在的Hive表里</a></td>
    </tr>
    <tr>
      <td> </td>
      <td><a href="http://sqoop.apache.org/docs/1.4.5/SqoopUserGuide.html#_literal_sqoop_export_literal">从 HDFS里面插入和更新数据到关系型数据库里面</a></td>
    </tr>
    <tr>
      <td> </td>
      <td><a href="https://flume.apache.org/FlumeUserGuide.html#starting-an-agent"> 给你一个Flume配置文件，启动一个 Flume agent</a></td>
    </tr>
    <tr>
      <td> </td>
      <td><a href="https://flume.apache.org/FlumeUserGuide.html#memory-channel">[给你一个配置好的 sink 和source, 配置一个 Flume 固定容量的内存 channel](https://flume.apache.org/FlumeUserGuide.html#memory-channel)</a></td>
    </tr>
    <tr>
      <td>数据转换</td>
      <td><a href="https://pig.apache.org/docs/r0.14.0/start.html#run">写出并执行一个pig脚本</a></td>
    </tr>
    <tr>
      <td> </td>
      <td><a href="https://pig.apache.org/docs/r0.14.0/basic.html#load"> 加载一个没有schema信息数据到Pig</a></td>
    </tr>
    <tr>
      <td> </td>
      <td><a href="https://pig.apache.org/docs/r0.14.0/basic.html#load">加载数据到Pig里面并关联一个schema</a></td>
    </tr>
    <tr>
      <td> </td>
      <td><a href="https://cwiki.apache.org/confluence/display/Hive/HCatalog+LoadStore">从Hive表里面加载数据到Pig</a></td>
    </tr>
    <tr>
      <td> </td>
      <td><a href="https://pig.apache.org/docs/r0.14.0/basic.html#foreach">通过Pig把加载的数据格式化</a></td>
    </tr>
    <tr>
      <td> </td>
      <td><a href="https://pig.apache.org/docs/r0.14.0/basic.html#foreach">转换数据匹配一个给定的Hive schema</a></td>
    </tr>
    <tr>
      <td> </td>
      <td><a href="https://pig.apache.org/docs/r0.14.0/basic.html#group">对 Pig 中数据进行分组</a></td>
    </tr>
    <tr>
      <td> </td>
      <td><a href="https://pig.apache.org/docs/r0.14.0/basic.html#filter">使用Pig移除记录里面关联的空值</a></td>
    </tr>
    <tr>
      <td> </td>
      <td><a href="https://pig.apache.org/docs/r0.14.0/basic.html#store">把 Pig 中的数据保存到HDFS中指定目录里面</a></td>
    </tr>
    <tr>
      <td> </td>
      <td><a href="https://cwiki.apache.org/confluence/display/Hive/HCatalog+LoadStore">把 Pig中的数据保存到Hive表里</a></td>
    </tr>
    <tr>
      <td> </td>
      <td><a href="https://pig.apache.org/docs/r0.14.0/basic.html#order-by">对Pig数据进行排序输出</a></td>
    </tr>
    <tr>
      <td> </td>
      <td><a href="https://pig.apache.org/docs/r0.14.0/basic.html#distinct">把Pig中关联重复数据移除</a></td>
    </tr>
    <tr>
      <td> </td>
      <td><a href="https://pig.apache.org/docs/r0.14.0/perf.html#parallel">对Pig MapReduce指定reduce任务数量</a></td>
    </tr>
    <tr>
      <td> </td>
      <td><a href="https://pig.apache.org/docs/r0.14.0/basic.html#join-innerandhttps://pig.apache.org/docs/r0.14.0/basic.html#join-outer">使用Pig进行关联操作</a></td>
    </tr>
    <tr>
      <td> </td>
      <td><a href="https://pig.apache.org/docs/r0.14.0/perf.html#replicated-joins">通过Pig join操作生成一个副本</a></td>
    </tr>
    <tr>
      <td> </td>
      <td><a href="https://pig.apache.org/docs/r0.14.0/perf.html#tez-mode"> 运行一个Pig 任务通过 Tez</a></td>
    </tr>
    <tr>
      <td> </td>
      <td><a href="https://pig.apache.org/docs/r0.14.0/basic.html#registerandhttps://pig.apache.org/docs/r0.14.0/udf.html#piggybank">在一个Pig 脚本内,通过注册一个Jar来使用定义的函数</a></td>
    </tr>
    <tr>
      <td> </td>
      <td><a href="https://pig.apache.org/docs/r0.14.0/basic.html#define-udfs">在Pig 脚本内, 使用定义的函数定义一个别名</a></td>
    </tr>
    <tr>
      <td> </td>
      <td><a href="https://pig.apache.org/docs/r0.14.0/basic.html#register">在一个Pig 脚本内, 执行一个用户定义函数</a></td>
    </tr>
    <tr>
      <td>数据分析</td>
      <td><a href="https://cwiki.apache.org/confluence/display/Hive/Tutorial">写并执行一个HIve查询</a></td>
    </tr>
    <tr>
      <td> </td>
      <td><a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL#LanguageManualDDL-Create/Drop/TruncateTable">定义一个内部表</a></td>
    </tr>
    <tr>
      <td> </td>
      <td><a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL#LanguageManualDDL-ExternalTables">定义一个扩展表</a></td>
    </tr>
    <tr>
      <td> </td>
      <td><a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL#LanguageManualDDL-PartitionedTables">定义一个分区表</a></td>
    </tr>
    <tr>
      <td> </td>
      <td><a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL#LanguageManualDDL-BucketedSortedTables">定义一个桶表</a></td>
    </tr>
    <tr>
      <td> </td>
      <td><a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL#LanguageManualDDL-CreateTableAsSelect(CTAS)">通过查询数据定义一个表</a></td>
    </tr>
    <tr>
      <td> </td>
      <td><a href="http://hortonworks.com/blog/orcfile-in-hdp-2-better-compression-better-performance/">使用ORCFile 文件格式定义一个表</a></td>
    </tr>
    <tr>
      <td> </td>
      <td><a href="http://hortonworks.com/blog/orcfile-in-hdp-2-better-compression-better-performance/">创建一个新的 ORCFile 表从一个非-ORCFile文件的 Hive 表</a></td>
    </tr>
    <tr>
      <td> </td>
      <td><a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL#LanguageManualDDL-RowFormat,StorageFormat,andSerDe">为Hive表指定一个存储格式</a></td>
    </tr>
    <tr>
      <td> </td>
      <td><a href="http://hortonworks.com/hadoop-tutorial/using-hive-data-analysis/">为Hive表指定一个分隔符</a></td>
    </tr>
    <tr>
      <td> </td>
      <td><a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DML#LanguageManualDML-Loadingfilesintotables">加载一个目录数据到Hive表中</a></td>
    </tr>
    <tr>
      <td> </td>
      <td><a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DML#LanguageManualDML-Loadingfilesintotables">从HDFS目录中加载数据到Hive表中</a></td>
    </tr>
    <tr>
      <td> </td>
      <td><a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DML#LanguageManualDML-InsertingdataintoHiveTablesfromqueries">把查询的结果加载数据到Hive表中</a></td>
    </tr>
    <tr>
      <td> </td>
      <td><a href="https://cwiki.apache.org/confluence/display/Hive/CompressedStorage">加载一个压缩数据到Hive表中</a></td>
    </tr>
    <tr>
      <td> </td>
      <td><a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DML#LanguageManualDML-Update"> 在Hive表中更新一行记录</a></td>
    </tr>
    <tr>
      <td> </td>
      <td><a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DML#LanguageManualDML-Delete">从 Hive表中删除一条数据</a></td>
    </tr>
    <tr>
      <td> </td>
      <td><a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DML#LanguageManualDML-InsertingvaluesintotablesfromSQL">插入一条数据到 Hive 表中</a></td>
    </tr>
    <tr>
      <td> </td>
      <td><a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+Joins">对Hive表进行Join操作</a></td>
    </tr>
    <tr>
      <td> </td>
      <td><a href="http://hortonworks.com/hadoop-tutorial/supercharging-interactive-queries-hive-tez/"> 通过Tez来执行Hive查询</a></td>
    </tr>
    <tr>
      <td> </td>
      <td><a href="http://hortonworks.com/hadoop-tutorial/supercharging-interactive-queries-hive-tez/">使用向量化来执行 Hive 查询</a></td>
    </tr>
    <tr>
      <td> </td>
      <td><a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+Explain">输出Hive执行计划操作结果</a></td>
    </tr>
    <tr>
      <td> </td>
      <td><a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+SubQueries"> 对Hive进行子查询操作</a></td>
    </tr>
    <tr>
      <td> </td>
      <td><a href="https://issues.apache.org/jira/browse/HIVE-1402">输出Hive统计、排序、交叉、多重操作的查询结果</a></td>
    </tr>
    <tr>
      <td> </td>
      <td><a href="https://cwiki.apache.org/confluence/display/Hive/AdminManual+Configuration#AdminManualConfiguration-ConfiguringHive">设置Hadoop 或Hive 配置属性通过Hive的查询结果中</a></td>
    </tr>
  </tbody>
</table>

<h2 id="other">Other</h2>

<p>Once the Hadoop cluster is up and running check the web-ui of the components as described below:</p>

<table>
  <tbody>
    <tr>
      <td>Daemon</td>
      <td>Web Interface</td>
      <td>Notes</td>
    </tr>
    <tr>
      <td>NameNode</td>
      <td>http://nn_host:port/</td>
      <td>Default HTTP port is 50070.</td>
    </tr>
    <tr>
      <td>ResourceManager</td>
      <td>http://rm_host:port/</td>
      <td>Default HTTP port is 8088.</td>
    </tr>
    <tr>
      <td>MapReduce JobHistory Server</td>
      <td>http://jhs_host:port/</td>
      <td>Default HTTP port is 19888.</td>
    </tr>
  </tbody>
</table>

<ul>
  <li>1 通过Web界面来查看NameNode运行状况，默认为：</li>
</ul>

<p><a href="h1:50070">NameNode</a> or</p>

<p><a href="http://192.168.71.128:50070">NameNode</a></p>

<ul>
  <li>2 通过Web界面来查看ResourceManager运行状况，默认为：</li>
</ul>

<p><a href="h1:8088">ResourceManager</a> or</p>

<p><a href="http://192.168.71.128:8088">ResourceManager</a></p>

<ul>
  <li>3 MapReduce JobHistory Server</li>
</ul>

<p><a href="h1:19888">MapReduce JobHistory Server</a> or</p>

<p><a href="http://192.168.71.128:19888">MapReduce JobHistory Server</a></p>

<h2 id="operating-the-hadoop-cluster">Operating the Hadoop Cluster</h2>

<p>Once all the necessary configuration is complete, distribute the files to the HADOOP_CONF_DIR directory on all the machines.</p>

<p>This section also describes the various Unix users who should be starting the various components and uses the same Unix accounts and groups used previously:</p>

<p><strong>Hadoop Startup</strong></p>

<p>To start a Hadoop cluster you will need to start both the HDFS and YARN cluster.</p>

<p>Format a new distributed filesystem as hdfs:</p>

<p>[hdfs]$ $HADOOP_PREFIX/bin/hdfs namenode -format <cluster_name>
Start the HDFS with the following command, run on the designated NameNode as hdfs:</cluster_name></p>

<p>[hdfs]$ $HADOOP_PREFIX/sbin/hadoop-daemon.sh –config $HADOOP_CONF_DIR –script hdfs start namenode
Run a script to start DataNodes on all slaves as root with a special environment variable HADOOP_SECURE_DN_USER set to hdfs:</p>

<p>[root]$ HADOOP_SECURE_DN_USER=hdfs $HADOOP_PREFIX/sbin/hadoop-daemon.sh –config $HADOOP_CONF_DIR –script hdfs start datanode
Start the YARN with the following command, run on the designated ResourceManager as yarn:</p>

<p>[yarn]$ $HADOOP_YARN_HOME/sbin/yarn-daemon.sh –config $HADOOP_CONF_DIR start resourcemanager
Run a script to start NodeManagers on all slaves as yarn:</p>

<p>[yarn]$ $HADOOP_YARN_HOME/sbin/yarn-daemon.sh –config $HADOOP_CONF_DIR start nodemanager
Start a standalone WebAppProxy server. Run on the WebAppProxy server as yarn. If multiple servers are used with load balancing it should be run on each of them:</p>

<p>[yarn]$ $HADOOP_YARN_HOME/bin/yarn start proxyserver –config $HADOOP_CONF_DIR
Start the MapReduce JobHistory Server with the following command, run on the designated server as mapred:</p>

<p>[mapred]$ $HADOOP_PREFIX/sbin/mr-jobhistory-daemon.sh start historyserver –config $HADOOP_CONF_DIR</p>

<p><strong>Hadoop Shutdown</strong></p>

<p>Stop the NameNode with the following command, run on the designated NameNode as hdfs:</p>

<p>[hdfs]$ $HADOOP_PREFIX/sbin/hadoop-daemon.sh –config $HADOOP_CONF_DIR –script hdfs stop namenode
Run a script to stop DataNodes on all slaves as root:</p>

<p>[root]$ $HADOOP_PREFIX/sbin/hadoop-daemon.sh –config $HADOOP_CONF_DIR –script hdfs stop datanode
Stop the ResourceManager with the following command, run on the designated ResourceManager as yarn:</p>

<p>[yarn]$ $HADOOP_YARN_HOME/sbin/yarn-daemon.sh –config $HADOOP_CONF_DIR stop resourcemanager
Run a script to stop NodeManagers on all slaves as yarn:</p>

<p>[yarn]$ $HADOOP_YARN_HOME/sbin/yarn-daemon.sh –config $HADOOP_CONF_DIR stop nodemanager
Stop the WebAppProxy server. Run on the WebAppProxy server as yarn. If multiple servers are used with load balancing it should be run on each of them:</p>

<p>[yarn]$ $HADOOP_YARN_HOME/bin/yarn stop proxyserver –config $HADOOP_CONF_DIR
Stop the MapReduce JobHistory Server with the following command, run on the designated server as mapred:</p>

<p>[mapred]$ $HADOOP_PREFIX/sbin/mr-jobhistory-daemon.sh stop historyserver –config $HADOOP_CONF_DIR</p>

        <div id="disqus_container">
            <class="comment"/>
<div id="disqus_thread"></div>
<script>
    /**
     *  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
     *  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
     */
    /*
    var disqus_config = function () {
        this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
        this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
    };
    */
    (function() {  // DON'T EDIT BELOW THIS LINE
        var d = document, s = d.createElement('script');

        s.src = '//wwwmachinelearningadvancecom.disqus.com/embed.js';

        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>
        </div>
   </div>

    <div class="sidenav">
        <h2>Blog</h2>
        <ul class="artical-list">
        
            <li><a href="/apply-analytics-master">How to start applying for Analytics / Data Science Masters in the US Universities?</a></li>
        
            <li><a href="/IP">IP</a></li>
        
            <li><a href="/LA3">Matrix operations and inverses</a></li>
        
            <li><a href="/sublime">sublime keyboard shortcuts</a></li>
        
            <li><a href="/dialogue_startup_business">dialogue about start up a business</a></li>
        
            <li><a href="/why-I-blog">Why I Blog？</a></li>
        
            <li><a href="/welcome">Welcome!</a></li>
        
        </ul>

        <h2>CFA</h2>
        <ul class="artical-list">
        
            <li><a href="/CFALevel1_AI">Lev1_AI_basic_concept</a></li>
        
            <li><a href="/CFALevel1_Derivative">Lev1_Derivative_basic_concept</a></li>
        
            <li><a href="/CFALevel1_FixedIncome">Lev1_FixedIncome_basic_concept</a></li>
        
            <li><a href="/CFALevel1_Equity">Lev1_Equity_basic_concept</a></li>
        
            <li><a href="/CFALevel1_Portfolio">Lev1_Portfolio_basic_concept</a></li>
        
            <li><a href="/CFALevel1_CorpFinance">Lev1_Corporate_Finance_basic_concept</a></li>
        
            <li><a href="/CFALevel1_FSA">Lev1_FSA_basic_concept</a></li>
        
            <li><a href="/CFALevel1_Economics">Lev1_Economics_basic_concept</a></li>
        
            <li><a href="/CFALevel1_Quants">Lev1_Quants_basic_concept</a></li>
        
        </ul>

        <h2>MLAdvance</h2>
        <ul class="artical-list">
        
            <li><a href="/hadoop_family_guide">Hadoop Learn Guide</a></li>
        
            <li><a href="/hadoop_family_site">Hadoop Resource</a></li>
        
            <li><a href="/hadoop_mahout">Hadoop Mahout</a></li>
        
            <li><a href="/hadoop_glossary">Hadoop 名词速览</a></li>
        
            <li><a href="/hadoop_family_zhihu">Hadoop生态圈</a></li>
        
            <li><a href="/hadoop_family">Hadoop Family</a></li>
        
            <li><a href="/Hadoop_Ecosystem_Table">Hadoop Ecosystem Table</a></li>
        
            <li><a href="/hadoop_vs_spark">Hadoop or Spark</a></li>
        
            <li><a href="/Python_numpy2">hackerrank_numpy_test</a></li>
        
            <li><a href="/Python_numpy">hackerrank_numpy</a></li>
        
            <li><a href="/my-weekend">This is a test!</a></li>
        
        </ul>
    </div>
</div>

<script src="/js/post.js" type="text/javascript"></script>


    <script type="text/javascript">
        $(function(){
            $('.home-follow').click(function(e){
                e.preventDefault();

                if($('.home-contact').is(':visible')){
                    $('.home-contact').slideUp(100);
                }else{
                    $('.home-contact').slideDown(100);
                }
            });
        })
    </script>
</body>
</html>
