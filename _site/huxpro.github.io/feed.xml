<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Lijun Yu's blog</title>
    <description>Everything about Lijun Yu.</description>
    <link>http://helloourworld.github.io/</link>
    <atom:link href="http://helloourworld.github.io/feed.xml" rel="self" type="application/rss+xml" />
    <pubDate>Thu, 18 Aug 2016 17:42:19 +0800</pubDate>
    <lastBuildDate>Thu, 18 Aug 2016 17:42:19 +0800</lastBuildDate>
    <generator>Jekyll v3.2.1</generator>
    
      <item>
        <title>Hadoop Tutorial ---- Spark入门实战系列--1.Spark及其生态圈简介</title>
        <description>&lt;h2 id=&quot;site&quot;&gt;Site&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;http://www.cnblogs.com/shishanyuan/p/4700615.html&quot;&gt;Spark入门实战系列–1.Spark及其生态圈简介&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Wed, 17 Aug 2016 00:00:00 +0800</pubDate>
        <link>http://helloourworld.github.io/hadoop_tutorial_3</link>
        <guid isPermaLink="true">http://helloourworld.github.io/hadoop_tutorial_3</guid>
        
        
        <category>blog</category>
        
      </item>
    
      <item>
        <title>Hadoop Tutorial ---- Components Required</title>
        <description>&lt;h2 id=&quot;section&quot;&gt;大数据培训&lt;/h2&gt;

&lt;p&gt;对象：大数据工程师、数据挖掘工程师、数据分析师、程序员…&lt;/p&gt;

&lt;h2 id=&quot;section-1&quot;&gt;学习内容&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;1 开源框架学习&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;类别&lt;/td&gt;
      &lt;td&gt;组件名称&lt;/td&gt;
      &lt;td&gt;学习等级&lt;/td&gt;
      &lt;td&gt;掌握程度&lt;/td&gt;
      &lt;td&gt;组件概述&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;文件系统&lt;/td&gt;
      &lt;td&gt;HDFS&lt;/td&gt;
      &lt;td&gt;一级&lt;/td&gt;
      &lt;td&gt;熟练&lt;/td&gt;
      &lt;td&gt;Hadoop分布式文件系统（Hadoop Distributed File System），提供高吞吐量的数据访问，适合大规模数据集方面的应用。&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;分布式编程&lt;/td&gt;
      &lt;td&gt;MapReduce&lt;/td&gt;
      &lt;td&gt;一级&lt;/td&gt;
      &lt;td&gt;熟练&lt;/td&gt;
      &lt;td&gt;提供快速并行处理大量数据的能力，是一种分布式数据处理模式和执行环境。&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;分布式编程&lt;/td&gt;
      &lt;td&gt;Pig&lt;/td&gt;
      &lt;td&gt;二级&lt;/td&gt;
      &lt;td&gt;熟练&lt;/td&gt;
      &lt;td&gt;Apache Pig是用来处理大规模数据的高级查询语言&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;分布式编程&lt;/td&gt;
      &lt;td&gt;Spark&lt;/td&gt;
      &lt;td&gt;特级&lt;/td&gt;
      &lt;td&gt;精通&lt;/td&gt;
      &lt;td&gt;基于内存进行计算的分布式计算框架。&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;分布式编程&lt;/td&gt;
      &lt;td&gt;Storm&lt;/td&gt;
      &lt;td&gt;二级&lt;/td&gt;
      &lt;td&gt;精通&lt;/td&gt;
      &lt;td&gt;Apache Storm是一个免费、开源的分布式实时计算系统&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;分布式编程&lt;/td&gt;
      &lt;td&gt;Tez&lt;/td&gt;
      &lt;td&gt;二级&lt;/td&gt;
      &lt;td&gt;熟练&lt;/td&gt;
      &lt;td&gt;Tez 是 Apache 最新的支持 DAG 作业的开源计算框架,它可以将多个有依赖的作业转换为一个作业从而大幅提升DAG作业的性能。&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;列存&lt;/td&gt;
      &lt;td&gt;Hbbase&lt;/td&gt;
      &lt;td&gt;二级&lt;/td&gt;
      &lt;td&gt;精通&lt;/td&gt;
      &lt;td&gt;提供海量数据存储功能，是一种构建在HDFS之上的分布式、面向列的存储系统。&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;文档存储&lt;/td&gt;
      &lt;td&gt;MongoDB&lt;/td&gt;
      &lt;td&gt;二级&lt;/td&gt;
      &lt;td&gt;掌握&lt;/td&gt;
      &lt;td&gt;MongoDB 是一个基于分布式文件存储的数据库，由C++语言编写，旨在为WEB应用提供可扩展的高性能数据存储解决方案。&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;键值存储&lt;/td&gt;
      &lt;td&gt;Redis&lt;/td&gt;
      &lt;td&gt;二级&lt;/td&gt;
      &lt;td&gt;熟练&lt;/td&gt;
      &lt;td&gt;Redis 是一个开源的使用ANSI C语言编写、支持网络、可基于内存亦可持久化的日志型、Key-Value数据库，并提供多种语言的API&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;数据处理&lt;/td&gt;
      &lt;td&gt;Hive&lt;/td&gt;
      &lt;td&gt;特级&lt;/td&gt;
      &lt;td&gt;精通&lt;/td&gt;
      &lt;td&gt;建立在Hadoop基础上的开源的数据仓库，提供类似SQL的Hive QL语言操作结构化数据存储服务和基本的数据分析服务。&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;数据处理&lt;/td&gt;
      &lt;td&gt;Flume&lt;/td&gt;
      &lt;td&gt;一级&lt;/td&gt;
      &lt;td&gt;精通&lt;/td&gt;
      &lt;td&gt;Flume是一个分布式、可靠、和高可用的海量日志采集、聚合和传输的系统。&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;数据处理&lt;/td&gt;
      &lt;td&gt;Sqoop&lt;/td&gt;
      &lt;td&gt;二级&lt;/td&gt;
      &lt;td&gt;熟练&lt;/td&gt;
      &lt;td&gt;Sqoop是一个数据库导入导出工具，可以将数据从hadoop导入到关系数据库，或从关系数据库将数据导入到hadoop中。&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;数据处理&lt;/td&gt;
      &lt;td&gt;KafKa&lt;/td&gt;
      &lt;td&gt;二级&lt;/td&gt;
      &lt;td&gt;熟练&lt;/td&gt;
      &lt;td&gt;一个分布式的、分区的、多副本的实时消息发布和订阅系统。提供可扩展、高吞吐、低延迟、高可靠的消息分发服务。&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;组件服务&lt;/td&gt;
      &lt;td&gt;zookeeper&lt;/td&gt;
      &lt;td&gt;二级&lt;/td&gt;
      &lt;td&gt;熟练&lt;/td&gt;
      &lt;td&gt;提供分布式、高可用性的协调服务能力。帮助系统避免单点故障，从而建立可靠的应用程序。&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;机器学习&lt;/td&gt;
      &lt;td&gt;Mahout&lt;/td&gt;
      &lt;td&gt;二级&lt;/td&gt;
      &lt;td&gt;熟练&lt;/td&gt;
      &lt;td&gt;提供一些可扩展的机器学习领域经典算法的实现，旨在帮助开发人员更加方便快捷地创建智能应用程序。Mahout包含许多实现，包括聚类、分类、推荐过滤、频繁子项挖掘。&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;系统部署&lt;/td&gt;
      &lt;td&gt;Ambari&lt;/td&gt;
      &lt;td&gt;三级&lt;/td&gt;
      &lt;td&gt;训练&lt;/td&gt;
      &lt;td&gt;Apache Ambari是一种基于Web的工具，支持Apache Hadoop集群的供应、管理和监控。Ambari目前已支持大多数Hadoop组件，包括HDFS、MapReduce、Hive、Pig、 Hbase、Zookeper、Sqoop和Hcatalog等。&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;系统部署&lt;/td&gt;
      &lt;td&gt;HUE&lt;/td&gt;
      &lt;td&gt;三级&lt;/td&gt;
      &lt;td&gt;了解&lt;/td&gt;
      &lt;td&gt;Hue是一个能够与Apache Hadoop交互的Web应用程序。一个开源的Apache Hadoop UI。&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;系统部署&lt;/td&gt;
      &lt;td&gt;Mesos&lt;/td&gt;
      &lt;td&gt;三级&lt;/td&gt;
      &lt;td&gt;了解&lt;/td&gt;
      &lt;td&gt;Mesos是Apache下的开源分布式资源管理框架,它被称为是分布式系统的内核。&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;ul&gt;
  &lt;li&gt;2 华为FI 及 Miner 学习&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;TODO&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;at-last&quot;&gt;At Last&lt;/h2&gt;

&lt;p&gt;Practice makes perfect! Do in action!&lt;/p&gt;
</description>
        <pubDate>Wed, 17 Aug 2016 00:00:00 +0800</pubDate>
        <link>http://helloourworld.github.io/hadoop_tutorial_1</link>
        <guid isPermaLink="true">http://helloourworld.github.io/hadoop_tutorial_1</guid>
        
        
        <category>blog</category>
        
      </item>
    
      <item>
        <title>LDA</title>
        <description>&lt;h2 id=&quot;lda&quot;&gt;LDA&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://www.quora.com/What-is-a-good-explanation-of-Latent-Dirichlet-Allocation&quot;&gt;What-is-a-good-explanation-of-Latent-Dirichlet-Allocation&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Fri, 12 Aug 2016 00:00:00 +0800</pubDate>
        <link>http://helloourworld.github.io/LDA</link>
        <guid isPermaLink="true">http://helloourworld.github.io/LDA</guid>
        
        
        <category>Blog</category>
        
      </item>
    
      <item>
        <title>Hadoop Mesos</title>
        <description>&lt;h2 id=&quot;mesosyarn&quot;&gt;mesos和yarn区别&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;http://blog.csdn.net/xinghun_4/article/details/47907161&quot;&gt;mesos和yarn区别&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://mesos.apache.org/gettingstarted/&quot;&gt;Getting Started&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;hadoop@NN01.HadoopVM
hadoop@DN01.HadoopVM
hadoop@DN02.HadoopVM&lt;/p&gt;
</description>
        <pubDate>Fri, 12 Aug 2016 00:00:00 +0800</pubDate>
        <link>http://helloourworld.github.io/hadoop_family_mesos</link>
        <guid isPermaLink="true">http://helloourworld.github.io/hadoop_family_mesos</guid>
        
        
        <category>MLAdvance</category>
        
      </item>
    
      <item>
        <title>Hadoop Learn Guide</title>
        <description>&lt;h2 id=&quot;section&quot;&gt;前言&lt;/h2&gt;

&lt;p&gt;大数据越来越火，客户要求越来越高。No废话，开始你的大数据之旅，请在不断的旅途当中为自己画饼！本培训主要针对的是有一定编程基础和有一定数据分析基础的同学，感觉有难度的地方请及时提出。&lt;/p&gt;

&lt;h2 id=&quot;section-1&quot;&gt;学习路径图&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;1 了解大数据生态圈及准备你的能力&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;2 开始你的装机之艰难旅程&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;3 组件针对性加强训练&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;4 组件定位与深挖&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;5 与时俱进及案例&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;6 数据挖掘相关课题方向加强训练&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;section-2&quot;&gt;附录&lt;/h2&gt;

&lt;h2 id=&quot;other&quot;&gt;Other&lt;/h2&gt;

</description>
        <pubDate>Tue, 09 Aug 2016 00:00:00 +0800</pubDate>
        <link>http://helloourworld.github.io/hadoop_family_guide</link>
        <guid isPermaLink="true">http://helloourworld.github.io/hadoop_family_guide</guid>
        
        
        <category>MLAdvance</category>
        
      </item>
    
      <item>
        <title>Hadoop Resource</title>
        <description>&lt;h2 id=&quot;apache&quot;&gt;Apache&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;http://hadoop.apache.org/docs/r2.6.4/hadoop-project-dist&quot;&gt;Apache docs&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;cloudera&quot;&gt;Cloudera&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;http://blog.cloudera.com/&quot;&gt;Cloudera Engineering Blog&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;storm&quot;&gt;Storm&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;http://www.cnblogs.com/panfeng412/tag/Storm/&quot;&gt;分布式计算 / 实时流计算 / NoSQL存储 (Email: ypf412@163.com, GitHub: https://github.com/ypf412)&lt;/a&gt;
## hortonworks&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://zh.hortonworks.com/&quot;&gt;hortonworks公司中文网&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://zh.hortonworks.com/training/certification/hdpcd-certification/&quot;&gt;THE HDPCD EXAM&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://ifeve.com/hortonworkshdp-hdpcd/&quot;&gt;Hortonworks(HDP)开发者认证&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;section&quot;&gt;考试内容列表&lt;/h3&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;类型&lt;/td&gt;
      &lt;td&gt;[任务]&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;数据获取&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-common/FileSystemShell.html#put&quot;&gt;通过Hadoop Shell把本地文件上传到HDFS&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-common/FileSystemShell.html#mkdir&quot;&gt;使用Hadoop Shell在HDFS上创建一个新的目录&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;http://sqoop.apache.org/docs/1.4.5/SqoopUserGuide.html#_literal_sqoop_import_literal&quot;&gt;从一个关系型数据库中导入数据到HDFS&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;http://sqoop.apache.org/docs/1.4.5/SqoopUserGuide.html#_free_form_query_imports&quot;&gt;导入关系型数据的查询结果到HDFS&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;http://sqoop.apache.org/docs/1.4.5/SqoopUserGuide.html#_importing_data_into_hive&quot;&gt;从一个关系型数据库中导入数据到一个新的或者已经存在的Hive表里&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;http://sqoop.apache.org/docs/1.4.5/SqoopUserGuide.html#_literal_sqoop_export_literal&quot;&gt;从 HDFS里面插入和更新数据到关系型数据库里面&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://flume.apache.org/FlumeUserGuide.html#starting-an-agent&quot;&gt; 给你一个Flume配置文件，启动一个 Flume agent&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://flume.apache.org/FlumeUserGuide.html#memory-channel&quot;&gt;[给你一个配置好的 sink 和source, 配置一个 Flume 固定容量的内存 channel](https://flume.apache.org/FlumeUserGuide.html#memory-channel)&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;数据转换&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://pig.apache.org/docs/r0.14.0/start.html#run&quot;&gt;写出并执行一个pig脚本&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://pig.apache.org/docs/r0.14.0/basic.html#load&quot;&gt; 加载一个没有schema信息数据到Pig&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://pig.apache.org/docs/r0.14.0/basic.html#load&quot;&gt;加载数据到Pig里面并关联一个schema&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/Hive/HCatalog+LoadStore&quot;&gt;从Hive表里面加载数据到Pig&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://pig.apache.org/docs/r0.14.0/basic.html#foreach&quot;&gt;通过Pig把加载的数据格式化&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://pig.apache.org/docs/r0.14.0/basic.html#foreach&quot;&gt;转换数据匹配一个给定的Hive schema&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://pig.apache.org/docs/r0.14.0/basic.html#group&quot;&gt;对 Pig 中数据进行分组&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://pig.apache.org/docs/r0.14.0/basic.html#filter&quot;&gt;使用Pig移除记录里面关联的空值&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://pig.apache.org/docs/r0.14.0/basic.html#store&quot;&gt;把 Pig 中的数据保存到HDFS中指定目录里面&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/Hive/HCatalog+LoadStore&quot;&gt;把 Pig中的数据保存到Hive表里&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://pig.apache.org/docs/r0.14.0/basic.html#order-by&quot;&gt;对Pig数据进行排序输出&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://pig.apache.org/docs/r0.14.0/basic.html#distinct&quot;&gt;把Pig中关联重复数据移除&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://pig.apache.org/docs/r0.14.0/perf.html#parallel&quot;&gt;对Pig MapReduce指定reduce任务数量&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://pig.apache.org/docs/r0.14.0/basic.html#join-innerandhttps://pig.apache.org/docs/r0.14.0/basic.html#join-outer&quot;&gt;使用Pig进行关联操作&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://pig.apache.org/docs/r0.14.0/perf.html#replicated-joins&quot;&gt;通过Pig join操作生成一个副本&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://pig.apache.org/docs/r0.14.0/perf.html#tez-mode&quot;&gt; 运行一个Pig 任务通过 Tez&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://pig.apache.org/docs/r0.14.0/basic.html#registerandhttps://pig.apache.org/docs/r0.14.0/udf.html#piggybank&quot;&gt;在一个Pig 脚本内,通过注册一个Jar来使用定义的函数&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://pig.apache.org/docs/r0.14.0/basic.html#define-udfs&quot;&gt;在Pig 脚本内, 使用定义的函数定义一个别名&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://pig.apache.org/docs/r0.14.0/basic.html#register&quot;&gt;在一个Pig 脚本内, 执行一个用户定义函数&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;数据分析&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/Hive/Tutorial&quot;&gt;写并执行一个HIve查询&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL#LanguageManualDDL-Create/Drop/TruncateTable&quot;&gt;定义一个内部表&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL#LanguageManualDDL-ExternalTables&quot;&gt;定义一个扩展表&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL#LanguageManualDDL-PartitionedTables&quot;&gt;定义一个分区表&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL#LanguageManualDDL-BucketedSortedTables&quot;&gt;定义一个桶表&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL#LanguageManualDDL-CreateTableAsSelect(CTAS)&quot;&gt;通过查询数据定义一个表&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;http://hortonworks.com/blog/orcfile-in-hdp-2-better-compression-better-performance/&quot;&gt;使用ORCFile 文件格式定义一个表&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;http://hortonworks.com/blog/orcfile-in-hdp-2-better-compression-better-performance/&quot;&gt;创建一个新的 ORCFile 表从一个非-ORCFile文件的 Hive 表&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL#LanguageManualDDL-RowFormat,StorageFormat,andSerDe&quot;&gt;为Hive表指定一个存储格式&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;http://hortonworks.com/hadoop-tutorial/using-hive-data-analysis/&quot;&gt;为Hive表指定一个分隔符&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DML#LanguageManualDML-Loadingfilesintotables&quot;&gt;加载一个目录数据到Hive表中&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DML#LanguageManualDML-Loadingfilesintotables&quot;&gt;从HDFS目录中加载数据到Hive表中&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DML#LanguageManualDML-InsertingdataintoHiveTablesfromqueries&quot;&gt;把查询的结果加载数据到Hive表中&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/Hive/CompressedStorage&quot;&gt;加载一个压缩数据到Hive表中&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DML#LanguageManualDML-Update&quot;&gt; 在Hive表中更新一行记录&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DML#LanguageManualDML-Delete&quot;&gt;从 Hive表中删除一条数据&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DML#LanguageManualDML-InsertingvaluesintotablesfromSQL&quot;&gt;插入一条数据到 Hive 表中&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/Hive/LanguageManual+Joins&quot;&gt;对Hive表进行Join操作&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;http://hortonworks.com/hadoop-tutorial/supercharging-interactive-queries-hive-tez/&quot;&gt; 通过Tez来执行Hive查询&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;http://hortonworks.com/hadoop-tutorial/supercharging-interactive-queries-hive-tez/&quot;&gt;使用向量化来执行 Hive 查询&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/Hive/LanguageManual+Explain&quot;&gt;输出Hive执行计划操作结果&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/Hive/LanguageManual+SubQueries&quot;&gt; 对Hive进行子查询操作&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-1402&quot;&gt;输出Hive统计、排序、交叉、多重操作的查询结果&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/Hive/AdminManual+Configuration#AdminManualConfiguration-ConfiguringHive&quot;&gt;设置Hadoop 或Hive 配置属性通过Hive的查询结果中&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&quot;other&quot;&gt;Other&lt;/h2&gt;

&lt;p&gt;Once the Hadoop cluster is up and running check the web-ui of the components as described below:&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Daemon&lt;/td&gt;
      &lt;td&gt;Web Interface&lt;/td&gt;
      &lt;td&gt;Notes&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;NameNode&lt;/td&gt;
      &lt;td&gt;http://nn_host:port/&lt;/td&gt;
      &lt;td&gt;Default HTTP port is 50070.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;ResourceManager&lt;/td&gt;
      &lt;td&gt;http://rm_host:port/&lt;/td&gt;
      &lt;td&gt;Default HTTP port is 8088.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;MapReduce JobHistory Server&lt;/td&gt;
      &lt;td&gt;http://jhs_host:port/&lt;/td&gt;
      &lt;td&gt;Default HTTP port is 19888.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;ul&gt;
  &lt;li&gt;1 通过Web界面来查看NameNode运行状况，默认为：&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a href=&quot;h1:50070&quot;&gt;NameNode&lt;/a&gt; or&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://192.168.71.128:50070&quot;&gt;NameNode&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;2 通过Web界面来查看ResourceManager运行状况，默认为：&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a href=&quot;h1:8088&quot;&gt;ResourceManager&lt;/a&gt; or&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://192.168.71.128:8088&quot;&gt;ResourceManager&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;3 MapReduce JobHistory Server&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a href=&quot;h1:19888&quot;&gt;MapReduce JobHistory Server&lt;/a&gt; or&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://192.168.71.128:19888&quot;&gt;MapReduce JobHistory Server&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;operating-the-hadoop-cluster&quot;&gt;Operating the Hadoop Cluster&lt;/h2&gt;

&lt;p&gt;Once all the necessary configuration is complete, distribute the files to the HADOOP_CONF_DIR directory on all the machines.&lt;/p&gt;

&lt;p&gt;This section also describes the various Unix users who should be starting the various components and uses the same Unix accounts and groups used previously:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Hadoop Startup&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;To start a Hadoop cluster you will need to start both the HDFS and YARN cluster.&lt;/p&gt;

&lt;p&gt;Format a new distributed filesystem as hdfs:&lt;/p&gt;

&lt;p&gt;[hdfs]$ $HADOOP_PREFIX/bin/hdfs namenode -format &lt;cluster_name&gt;
Start the HDFS with the following command, run on the designated NameNode as hdfs:&lt;/cluster_name&gt;&lt;/p&gt;

&lt;p&gt;[hdfs]$ $HADOOP_PREFIX/sbin/hadoop-daemon.sh –config $HADOOP_CONF_DIR –script hdfs start namenode
Run a script to start DataNodes on all slaves as root with a special environment variable HADOOP_SECURE_DN_USER set to hdfs:&lt;/p&gt;

&lt;p&gt;[root]$ HADOOP_SECURE_DN_USER=hdfs $HADOOP_PREFIX/sbin/hadoop-daemon.sh –config $HADOOP_CONF_DIR –script hdfs start datanode
Start the YARN with the following command, run on the designated ResourceManager as yarn:&lt;/p&gt;

&lt;p&gt;[yarn]$ $HADOOP_YARN_HOME/sbin/yarn-daemon.sh –config $HADOOP_CONF_DIR start resourcemanager
Run a script to start NodeManagers on all slaves as yarn:&lt;/p&gt;

&lt;p&gt;[yarn]$ $HADOOP_YARN_HOME/sbin/yarn-daemon.sh –config $HADOOP_CONF_DIR start nodemanager
Start a standalone WebAppProxy server. Run on the WebAppProxy server as yarn. If multiple servers are used with load balancing it should be run on each of them:&lt;/p&gt;

&lt;p&gt;[yarn]$ $HADOOP_YARN_HOME/bin/yarn start proxyserver –config $HADOOP_CONF_DIR
Start the MapReduce JobHistory Server with the following command, run on the designated server as mapred:&lt;/p&gt;

&lt;p&gt;[mapred]$ $HADOOP_PREFIX/sbin/mr-jobhistory-daemon.sh start historyserver –config $HADOOP_CONF_DIR&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Hadoop Shutdown&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Stop the NameNode with the following command, run on the designated NameNode as hdfs:&lt;/p&gt;

&lt;p&gt;[hdfs]$ $HADOOP_PREFIX/sbin/hadoop-daemon.sh –config $HADOOP_CONF_DIR –script hdfs stop namenode
Run a script to stop DataNodes on all slaves as root:&lt;/p&gt;

&lt;p&gt;[root]$ $HADOOP_PREFIX/sbin/hadoop-daemon.sh –config $HADOOP_CONF_DIR –script hdfs stop datanode
Stop the ResourceManager with the following command, run on the designated ResourceManager as yarn:&lt;/p&gt;

&lt;p&gt;[yarn]$ $HADOOP_YARN_HOME/sbin/yarn-daemon.sh –config $HADOOP_CONF_DIR stop resourcemanager
Run a script to stop NodeManagers on all slaves as yarn:&lt;/p&gt;

&lt;p&gt;[yarn]$ $HADOOP_YARN_HOME/sbin/yarn-daemon.sh –config $HADOOP_CONF_DIR stop nodemanager
Stop the WebAppProxy server. Run on the WebAppProxy server as yarn. If multiple servers are used with load balancing it should be run on each of them:&lt;/p&gt;

&lt;p&gt;[yarn]$ $HADOOP_YARN_HOME/bin/yarn stop proxyserver –config $HADOOP_CONF_DIR
Stop the MapReduce JobHistory Server with the following command, run on the designated server as mapred:&lt;/p&gt;

&lt;p&gt;[mapred]$ $HADOOP_PREFIX/sbin/mr-jobhistory-daemon.sh stop historyserver –config $HADOOP_CONF_DIR&lt;/p&gt;
</description>
        <pubDate>Sat, 06 Aug 2016 00:00:00 +0800</pubDate>
        <link>http://helloourworld.github.io/hadoop_family_site</link>
        <guid isPermaLink="true">http://helloourworld.github.io/hadoop_family_site</guid>
        
        
        <category>MLAdvance</category>
        
      </item>
    
      <item>
        <title>Hadoop Mahout</title>
        <description>&lt;h2 id=&quot;mahout&quot;&gt;开始 Mahout&lt;/h2&gt;

&lt;p&gt;Mahout has prepared a bunch of examples and tutorials for users to quickly learn how to use its machine learning algorithms.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/mahout-logo-brudman.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;mahout-&quot;&gt;Mahout 支持的算法&lt;/h2&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Mahout 0.12.0 Features by Engine¶&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;Single Machine&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;MapReduce&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;Spark&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;H2O&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;Flink&lt;/strong&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Mahout Math-Scala Core Library and Scala DSL&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Mahout Distributed BLAS. Distributed Row Matrix API with R and Matlab like operators. Distributed ALS, SPCA, SSVD, thin-QR. Similarity Analysis.&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Mahout Interactive Shell&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Interactive REPL shell for Spark optimized Mahout DSL&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Collaborative Filtering with CLI drivers&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;User-Based Collaborative Filtering&lt;/td&gt;
      &lt;td&gt;弃用&lt;/td&gt;
      &lt;td&gt;弃用&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Item-Based Collaborative Filtering&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Matrix Factorization with ALS&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Matrix Factorization with ALS on Implicit Feedback&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Weighted Matrix Factorization, SVD++&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Classification with CLI drivers&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Logistic Regression - trained via SGD&lt;/td&gt;
      &lt;td&gt;弃用&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Naive Bayes / Complementary Naive Bayes&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;弃用&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Hidden Markov Models&lt;/td&gt;
      &lt;td&gt;弃用&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Clustering with CLI drivers&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Canopy Clustering&lt;/td&gt;
      &lt;td&gt;弃用&lt;/td&gt;
      &lt;td&gt;弃用&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;k-Means Clustering&lt;/td&gt;
      &lt;td&gt;弃用&lt;/td&gt;
      &lt;td&gt;弃用&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Fuzzy k-Means&lt;/td&gt;
      &lt;td&gt;弃用&lt;/td&gt;
      &lt;td&gt;弃用&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Streaming k-Means&lt;/td&gt;
      &lt;td&gt;弃用&lt;/td&gt;
      &lt;td&gt;弃用&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Spectral Clustering&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;弃用&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Dimensionality Reduction&lt;/strong&gt; note: most scala-based dimensionality reduction algorithms are available through the Mahout Math-Scala Core Library for all engines&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Singular Value Decomposition&lt;/td&gt;
      &lt;td&gt;弃用&lt;/td&gt;
      &lt;td&gt;弃用&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Lanczos Algorithm&lt;/td&gt;
      &lt;td&gt;弃用&lt;/td&gt;
      &lt;td&gt;弃用&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Stochastic SVD&lt;/td&gt;
      &lt;td&gt;弃用&lt;/td&gt;
      &lt;td&gt;弃用&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;PCA (via Stochastic SVD)&lt;/td&gt;
      &lt;td&gt;弃用&lt;/td&gt;
      &lt;td&gt;弃用&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;QR Decomposition&lt;/td&gt;
      &lt;td&gt;弃用&lt;/td&gt;
      &lt;td&gt;弃用&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Topic Models&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Latent Dirichlet Allocation&lt;/td&gt;
      &lt;td&gt;弃用&lt;/td&gt;
      &lt;td&gt;弃用&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Miscellaneous&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;RowSimilarityJob&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;弃用&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Collocations&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;弃用&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Sparse TF-IDF Vectors from Text&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;弃用&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;XML Parsing&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;弃用&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Email Archive Parsing&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;弃用&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Evolutionary Processes&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;a href=&quot;&amp;quot;http://mahout.apache.org/users/basics/algorithms.html&amp;quot;&quot;&gt;mahout algorithms&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;section&quot;&gt;说明&lt;/h2&gt;
</description>
        <pubDate>Thu, 04 Aug 2016 00:00:00 +0800</pubDate>
        <link>http://helloourworld.github.io/hadoop_mahout</link>
        <guid isPermaLink="true">http://helloourworld.github.io/hadoop_mahout</guid>
        
        
        <category>MLAdvance</category>
        
      </item>
    
      <item>
        <title>Hadoop 名词速览</title>
        <description>&lt;h2 id=&quot;hadoop&quot;&gt;Hadoop产品名词速览（不断补充中…）&lt;/h2&gt;

&lt;p&gt;Apache Hadoop: 是Apache开源组织的一个分布式计算开源框架，提供了一个分布式文件系统子项目(HDFS)和支持MapReduce分布式计算的软件架构。&lt;/p&gt;

&lt;p&gt;Apache Hive: 是基于Hadoop的一个数据仓库工具，可以将结构化的数据文件映射为一张数据库表，通过类SQL语句快速实现简单的MapReduce统计，不必开发专门的MapReduce应用，十分适合数据仓库的统计分析。&lt;/p&gt;

&lt;p&gt;Apache Pig: 是一个基于Hadoop的大规模数据分析工具，它提供的SQL-LIKE语言叫Pig Latin，该语言的编译器会把类SQL的数据分析请求转换为一系列经过优化处理的MapReduce运算。&lt;/p&gt;

&lt;p&gt;Apache HBase: 是一个高可靠性、高性能、面向列、可伸缩的分布式存储系统，利用HBase技术可在廉价PC Server上搭建起大规模结构化存储集群。&lt;/p&gt;

&lt;p&gt;Apache Sqoop: 是一个用来将Hadoop和关系型数据库中的数据相互转移的工具，可以将一个关系型数据库（MySQL ,Oracle ,Postgres等）中的数据导进到Hadoop的HDFS中，也可以将HDFS的数据导进到关系型数据库中。&lt;/p&gt;

&lt;p&gt;Apache Zookeeper: 是一个为分布式应用所设计的分布的、开源的协调服务，它主要是用来解决分布式应用中经常遇到的一些数据管理问题，简化分布式应用协调及其管理的难度，提供高性能的分布式服务&lt;/p&gt;

&lt;p&gt;Apache Mahout:是基于Hadoop的机器学习和数据挖掘的一个分布式框架。Mahout用MapReduce实现了部分数据挖掘算法，解决了并行挖掘的问题。&lt;/p&gt;

&lt;p&gt;Apache Cassandra:是一套开源分布式NoSQL数据库系统。它最初由Facebook开发，用于储存简单格式数据，集Google BigTable的数据模型与Amazon Dynamo的完全分布式的架构于一身&lt;/p&gt;

&lt;p&gt;Apache Avro: 是一个数据序列化系统，设计用于支持数据密集型，大批量数据交换的应用。Avro是新的数据序列化格式与传输工具，将逐步取代Hadoop原有的IPC机制&lt;/p&gt;

&lt;p&gt;Apache Ambari: 是一种基于Web的工具，支持Hadoop集群的供应、管理和监控。&lt;/p&gt;

&lt;p&gt;Apache Chukwa: 是一个开源的用于监控大型分布式系统的数据收集系统，它可以将各种各样类型的数据收集成适合 Hadoop 处理的文件保存在 HDFS 中供 Hadoop 进行各种 MapReduce 操作。&lt;/p&gt;

&lt;p&gt;Apache Hama: 是一个基于HDFS的BSP（Bulk Synchronous Parallel)并行计算框架, Hama可用于包括图、矩阵和网络算法在内的大规模、大数据计算。&lt;/p&gt;

&lt;p&gt;Apache Flume: 是一个分布的、可靠的、高可用的海量日志聚合的系统，可用于日志数据收集，日志数据处理，日志数据传输。&lt;/p&gt;

&lt;p&gt;Apache Giraph: 是一个可伸缩的分布式迭代图处理系统， 基于Hadoop平台，灵感来自 BSP (bulk synchronous parallel) 和 Google 的 Pregel。&lt;/p&gt;

&lt;p&gt;Apache Oozie: 是一个工作流引擎服务器, 用于管理和协调运行在Hadoop平台上（HDFS、Pig和MapReduce）的任务。&lt;/p&gt;

&lt;p&gt;Apache Crunch: 是基于Google的FlumeJava库编写的Java库，用于创建MapReduce程序。与Hive，Pig类似，Crunch提供了用于实现如连接数据、执行聚合和排序记录等常见任务的模式库&lt;/p&gt;

&lt;p&gt;Apache Whirr: 是一套运行于云服务的类库（包括Hadoop），可提供高度的互补性。Whirr学支持Amazon EC2和Rackspace的服务。&lt;/p&gt;

&lt;p&gt;Apache Bigtop: 是一个对Hadoop及其周边生态进行打包，分发和测试的工具。&lt;/p&gt;

&lt;p&gt;Apache HCatalog: 是基于Hadoop的数据表和存储管理，实现中央的元数据和模式管理，跨越Hadoop和RDBMS，利用Pig和Hive提供关系视图。Cloudera Hue: 是一个基于WEB的监控和管理系统，实现对HDFS，MapReduce/YARN, HBase, Hive, Pig的web化操作和管理。&lt;/p&gt;

&lt;h2 id=&quot;section&quot;&gt;不当之处，请指正&lt;/h2&gt;
</description>
        <pubDate>Thu, 04 Aug 2016 00:00:00 +0800</pubDate>
        <link>http://helloourworld.github.io/hadoop_glossary</link>
        <guid isPermaLink="true">http://helloourworld.github.io/hadoop_glossary</guid>
        
        
        <category>MLAdvance</category>
        
      </item>
    
      <item>
        <title>Hadoop生态圈</title>
        <description>&lt;h2 id=&quot;hadoophivespark-&quot;&gt;如何用形象的比喻描述大数据的技术生态？Hadoop、Hive、Spark 之间是什么关系？&lt;/h2&gt;

&lt;p&gt;请参照知乎原文，&lt;a href=&quot;https://www.zhihu.com/question/27974418&quot;&gt;链接&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Thu, 04 Aug 2016 00:00:00 +0800</pubDate>
        <link>http://helloourworld.github.io/hadoop_family_zhihu</link>
        <guid isPermaLink="true">http://helloourworld.github.io/hadoop_family_zhihu</guid>
        
        
        <category>MLAdvance</category>
        
      </item>
    
      <item>
        <title>Hadoop Family</title>
        <description>&lt;p&gt;Hadoop家族产品，很多。常用的项目包括Hadoop, Hive, Pig, HBase, Sqoop, Mahout, Zookeeper, Avro, Ambari, Chukwa，YARN, Hcatalog, Oozie, Cassandra, Hama, Whirr, Flume, Bigtop, Crunch, Hue, Spark, Streaming, Kafka等。对照&lt;a href=&quot;/Hadoop_Ecosystem_Table&quot;&gt;Hadoop_Ecosystem_Table&lt;/a&gt;,我们将其分类为：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;1	分布式文件存储系统&lt;/li&gt;
  &lt;li&gt;2 分布式编程&lt;/li&gt;
  &lt;li&gt;3 数据库[列存储、文档存储、流存储、KV存储、图数存储]&lt;/li&gt;
  &lt;li&gt;4 新型数据库&lt;/li&gt;
  &lt;li&gt;5 SQL on Hadoop&lt;/li&gt;
  &lt;li&gt;6 数据处理&lt;/li&gt;
  &lt;li&gt;7 服务系统&lt;/li&gt;
  &lt;li&gt;8 调度系统&lt;/li&gt;
  &lt;li&gt;9 机器学习&lt;/li&gt;
  &lt;li&gt;10 其它[标杆及问答、安全、元数据、系统部署、应用、部署架构等等]&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;每一分类都是方向上的概括，如同炊具，在其下面都包含多种细类，每一细类旨在解决不同的问题，如同具体的高压锅，面包机等。这一比喻请参照&lt;a href=&quot;/hadoop_family_zhihu&quot;&gt;Hadoop生态圈&lt;/a&gt;的描述。&lt;/p&gt;

&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;以下图片为广泛传阅的生态图，较早为2015年，出处不详。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/Hadoop-Ecosystem-Map_2015.gif&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;以下图片为最新且常用的生态图，图片源自&lt;a href=&quot;https://www.safaribooksonline.com/library/view/hadoop-essentials/9781784396688/ch02s05.html&quot;&gt;Safari&lt;/a&gt;
&lt;img src=&quot;/images/Hadoop-Ecosystem-Map_2016.jpg&quot; alt=&quot;&quot; /&gt;，是本文主要介绍的部分。&lt;/p&gt;

&lt;h2 id=&quot;hadoop-core&quot;&gt;1 Hadoop Core&lt;/h2&gt;

&lt;p&gt;主要包括HDFS，MapReduce, HBase.&lt;/p&gt;

&lt;h3 id=&quot;hdfs&quot;&gt;1 HDFS&lt;/h3&gt;

&lt;p&gt;Hadoop Distributed File System (HDFS™): A distributed file system that provides high-throughput access to application data. HDFS 是一个能够面向大规模数据使用的，可进行扩展的文件存储与传递系统，是一种允许文件通过网络在多台主机上分享的文件系统，可让多机器上的多用户分享文件和存储空间。实际上，通过网络来访问文件的动作，在程序与用户看来，就像是访问本地的磁盘一般。即使系统中有某些节点脱机，整体来说系统仍然可以持续运作而不会有数据损失。&lt;/p&gt;

&lt;h4 id=&quot;hdfs-1&quot;&gt;1 HDFS体系结构&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;/images/hdfs_architecture.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;blockquote&gt;
      &lt;p&gt;1 Namenode&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Namenode是整个文件系统的管理节点。它维护着整个文件系统的文件目录树，文件/目录的元信息和每个文件对应的数据块列表, 接收用户的操作请求。&lt;/p&gt;

&lt;p&gt;文件包括：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;gt; ①fsimage:元数据镜像文件。存储某一时段NameNode内存元数据信息。
&amp;gt; ②edits:操作日志文件。
&amp;gt; ③fstime:保存最近一次checkpoint的时间
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;以上这些文件是保存在linux的文件系统中。通过hdfs-site.xml的dfs.namenode.name.dir属性进行设置。&lt;/p&gt;

&lt;p&gt;查看NameNode的fsimage与edits内容&lt;/p&gt;

&lt;p&gt;这个两个文件中的内容使用普通文本编辑器是无法直接查看的，幸运的是hadoop为此准备了专门的工具用于查看文件的内容，这些工具分别为oev和oiv，可以使用hdfs调用执行。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;`
# 启动服务器：bin/hdfs oiv -i 某个fsimage文件

bash$ bin/hdfs oiv -i fsimage
14/04/07 13:25:14 INFO offlineImageViewer.WebImageViewer: WebImageViewer started.
Listening on /127.0.0.1:5978. Press Ctrl+C to stop the viewer.

# 查看内容：bin/hdfs dfs -ls -R webhdfs://127.0.0.1:5978/

bash$ bin/hdfs dfs -ls webhdfs://127.0.0.1:5978/
Found 2 items
drwxrwx–* - root supergroup 0 2014-03-26 20:16 webhdfs://127.0.0.1:5978/tmp
drwxr-xr-x - root supergroup 0 2014-03-31 14:08 webhdfs://127.0.0.1:5978/user
`

`# 导出fsimage的内容：bin/hdfs oiv -p XML -i
tmp/dfs/name/current/fsimage_0000000000000000055 -o fsimage.xml

bash$ bin/hdfs oiv -p XML -i fsimage -o fsimage.xml
0000055 -o fsimage.xml

# 查看edtis的内容：bin/hdfs oev -i
tmp/dfs/name/current/edits_0000000000000000057-0000000000000000186 -o edits.xml

bash$ bin/hdfs oev -i
tmp/dfs/name/current/edits_0000000000000000057-0000000000000000186 -o edits.xml
`
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;blockquote&gt;
      &lt;p&gt;2 Datanode&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;提供真实文件数据的存储服务。&lt;/p&gt;

&lt;p&gt;文件块（ block）： 最基本的存储单位。&lt;/p&gt;

&lt;p&gt;对于文件内容而言，一个文件的长度大小是size，那么从文件的０偏移开始，按照固定的大小，顺序对文件进行划分并编号，划分好的每一个块称一个Block。 HDFS默认Block大小是128MB， 因此，一个256MB文件，共有256/128=2个Block.&lt;/p&gt;

&lt;p&gt;与普通文件系统不同的是，在 HDFS中，如果一个文件小于一个数据块的大小，并不占用整个数据块存储空间。&lt;/p&gt;

&lt;p&gt;Replication：多复本。默认是三个。通过hdfs-site.xml的dfs.replication属性进行设置。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;blockquote&gt;
      &lt;p&gt;3 数据存储： staging&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;HDFS client上传数据到HDFS时，首先，在本地缓存数据，当数据达到一个block大小时，请求NameNode分配一个block。 NameNode会把block所在的DataNode的地址告诉HDFS client。 HDFS client会直接和DataNode通信，把数据写到DataNode节点一个block文件中。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;blockquote&gt;
      &lt;p&gt;4 数据存储：读文件操作&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;imageshdfsreadjpg&quot;&gt;&lt;img src=&quot;/images/hdfs_read.jpg&quot; alt=&quot;&quot; /&gt;&lt;/h2&gt;

&lt;blockquote&gt;
  &lt;blockquote&gt;
    &lt;p&gt;1.首先调用FileSystem对象的open方法，其实是一个DistributedFileSystem的实例。&lt;/p&gt;
  &lt;/blockquote&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;blockquote&gt;
    &lt;p&gt;2.DistributedFileSystem通过rpc获得文件的第一批block的locations，同一个block按照重复数会返回多个locations，这些locations按照hadoop拓扑结构排序，距离客户端近的排在前面。&lt;/p&gt;
  &lt;/blockquote&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;blockquote&gt;
    &lt;p&gt;3.前两步会返回一个FSDataInputStream对象，该对象会被封装DFSInputStream对象，DFSInputStream可以方便的管理datanode和namenode数据流。客户端调用read方法，DFSInputStream最会找出离客户端最近的datanode并连接。&lt;/p&gt;
  &lt;/blockquote&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;blockquote&gt;
    &lt;p&gt;4.数据从datanode源源不断的流向客户端。&lt;/p&gt;
  &lt;/blockquote&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;blockquote&gt;
    &lt;p&gt;5.如果第一块的数据读完了，就会关闭指向第一块的datanode连接，接着读取下一块。这些操作对客户端来说是透明的，客户端的角度看来只是读一个持续不断的流。&lt;/p&gt;
  &lt;/blockquote&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;blockquote&gt;
    &lt;p&gt;6.如果第一批block都读完了， DFSInputStream就会去namenode拿下一批block的locations，然后继续读，如果所有的块都读完，这时就会关闭掉所有的流。&lt;/p&gt;
  &lt;/blockquote&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;blockquote&gt;
    &lt;p&gt;[Alert!]如果在读数据的时候， DFSInputStream和datanode的通讯发生异常，就会尝试正在读的block的排序第二近的datanode,并且会记录哪个datanode发生错误，剩余的blocks读的时候就会直接跳过该datanode。 DFSInputStream也会检查block数据校验和，如果发现一个坏的block,就会先报告到namenode节点，然后DFSInputStream在其他的datanode上读该block的镜像。&lt;/p&gt;
  &lt;/blockquote&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;blockquote&gt;
    &lt;p&gt;该设计就是客户端直接连接datanode来检索数据并且namenode来负责为每一个block提供最优的datanode， namenode仅仅处理block location的请求，这些信息都加载在namenode的内存中，hdfs通过datanode集群可以承受大量客户端的并发访问。&lt;/p&gt;
  &lt;/blockquote&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;blockquote&gt;
      &lt;p&gt;5 数据存储：写文件操作&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/images/hdfs_write.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;blockquote&gt;
    &lt;p&gt;1.客户端通过调用DistributedFileSystem的create方法创建新文件。&lt;/p&gt;
  &lt;/blockquote&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;blockquote&gt;
    &lt;p&gt;2.DistributedFileSystem通过RPC调用namenode去创建一个没有blocks关联的新文件，创建前， namenode会做各种校验，比如文件是否存在，客户端有无权限去创建等。如果校验通过， namenode就会记录下新文件，否则就会抛出IO异常。&lt;/p&gt;
  &lt;/blockquote&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;blockquote&gt;
    &lt;p&gt;3.前两步结束后，会返回FSDataOutputStream的对象，与读文件的时候相似， FSDataOutputStream被封装成DFSOutputStream。DFSOutputStream可以协调namenode和datanode。客户端开始写数据到DFSOutputStream，DFSOutputStream会把数据切成一个个小的packet，然后排成队列data quene。&lt;/p&gt;
  &lt;/blockquote&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;blockquote&gt;
    &lt;p&gt;4.DataStreamer会去处理接受data quene，它先询问namenode这个新的block最适合存储的在哪几个datanode里（比如重复数是3，那么就找到3个最适合的datanode），把他们排成一个pipeline。DataStreamer把packet按队列输出到管道的第一个datanode中，第一个datanode又把packet输出到第二个datanode中，以此类推。&lt;/p&gt;
  &lt;/blockquote&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;blockquote&gt;
    &lt;p&gt;5.DFSOutputStream还有一个对列叫ack quene，也是由packet组成，等待datanode的收到响应，当pipeline中的所有datanode都表示已经收到的时候，这时akc quene才会把对应的packet包移除掉。&lt;/p&gt;
  &lt;/blockquote&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;blockquote&gt;
    &lt;p&gt;如果在写的过程中某个datanode发生错误，会采取以下几步：&lt;/p&gt;
  &lt;/blockquote&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;blockquote&gt;
    &lt;ul&gt;
      &lt;li&gt;1) pipeline被关闭掉；&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/blockquote&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;blockquote&gt;
    &lt;ul&gt;
      &lt;li&gt;2)为了防止防止丢包ack quene里的packet会同步到data quene里；&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/blockquote&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;blockquote&gt;
    &lt;ul&gt;
      &lt;li&gt;3)把产生错误的datanode上当前在写但未完成的block删掉；&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/blockquote&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;blockquote&gt;
    &lt;ul&gt;
      &lt;li&gt;4)block剩下的部分被写到剩下的两个正常的datanode中；&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/blockquote&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;blockquote&gt;
    &lt;ul&gt;
      &lt;li&gt;5)namenode找到另外的datanode去创建这个块的复制。当然，这些操作对客户端来说是无感知的。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/blockquote&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;blockquote&gt;
    &lt;p&gt;6.客户端完成写数据后调用close方法关闭写入流。&lt;/p&gt;
  &lt;/blockquote&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;blockquote&gt;
    &lt;p&gt;7.DataStreamer把剩余得包都刷到pipeline里，然后等待ack信息，收到最后一个ack后，通知datanode把文件标视为已完成。&lt;/p&gt;
  &lt;/blockquote&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;blockquote&gt;
    &lt;p&gt;注意：客户端执行write操作后，写完的block才是可见的，正在写的block对客户端是不可见的，只有调用sync方法，客户端才确保该文件的写操作已经全部完成，当客户端调用close方法时，会默认调用sync方法。是否需要手动调用取决你根据程序需要在数据健壮性和吞吐率之间的权衡。&lt;/p&gt;
  &lt;/blockquote&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;blockquote&gt;
      &lt;p&gt;5 HDFS常用命令&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a href=&quot;http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-common/FileSystemShell.html&quot;&gt;HDFS 常用命令: 官网&lt;/a&gt;&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;类型&lt;/td&gt;
      &lt;td&gt;[任务]&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;数据获取&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-common/FileSystemShell.html#put&quot;&gt;通过Hadoop Shell把本地文件上传到HDFS&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-common/FileSystemShell.html#mkdir&quot;&gt;使用Hadoop Shell在HDFS上创建一个新的目录&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;http://sqoop.apache.org/docs/1.4.5/SqoopUserGuide.html#_literal_sqoop_import_literal&quot;&gt;从一个关系型数据库中导入数据到HDFS&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;http://sqoop.apache.org/docs/1.4.5/SqoopUserGuide.html#_free_form_query_imports&quot;&gt;导入关系型数据的查询结果到HDFS&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;http://sqoop.apache.org/docs/1.4.5/SqoopUserGuide.html#_importing_data_into_hive&quot;&gt;从一个关系型数据库中导入数据到一个新的或者已经存在的Hive表里&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;http://sqoop.apache.org/docs/1.4.5/SqoopUserGuide.html#_literal_sqoop_export_literal&quot;&gt;从 HDFS里面插入和更新数据到关系型数据库里面&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://flume.apache.org/FlumeUserGuide.html#starting-an-agent&quot;&gt; 给你一个Flume配置文件，启动一个 Flume agent&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://flume.apache.org/FlumeUserGuide.html#memory-channel&quot;&gt;给你一个配置好的 sink 和source, 配置一个 Flume 固定容量的内存 channel&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&quot;mapreduce&quot;&gt;2 MapReduce&lt;/h3&gt;

&lt;h4 id=&quot;explain-mapreduce-in-5-minutes&quot;&gt;Explain Map/Reduce in 5 minutes&lt;/h4&gt;

&lt;p&gt;原文链接: &lt;a href=&quot;http://www.csdn.net/article/2013-01-07/2813477-confused-about-mapreduce&quot;&gt;http://www.csdn.net/article/2013-01-07/2813477-confused-about-mapreduce&lt;/a&gt; by Aurelien.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;blockquote&gt;
      &lt;p&gt;1 Map/Reduce 有3个阶段 : Map/Shuffle/Reduce&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Shuffle部分由Hadoop的自动完成，我们只需要实现Map和Reduce部分。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;blockquote&gt;
      &lt;p&gt;2 Map部分的输入&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/images/mapred_mapinput.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;图上的城市名称作为key值，所属州以及城市均温为key的value值。ps: 请自动脑补python的dict, jason.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;blockquote&gt;
      &lt;p&gt;3 Map部分的输出&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/images/mapred_mapoutput.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;图上显示的Map部分的输出是根据最终我们想要的结果来实现的。我们要得到每个州的平均值，所以根据每个州来进行新的key/value设计。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;blockquote&gt;
      &lt;p&gt;4 Shuffle部分&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/images/mapred_shuffle.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Now, the shuffle task will run on the output of the Map task. It is going to group all the values by Key, and you’ll get a List&lt;Value&gt;.&lt;/Value&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;blockquote&gt;
      &lt;p&gt;5 Rduce部分&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Reduce部分的输入为以上Shuffle部分的输出。&lt;/p&gt;

&lt;p&gt;Reduce任务是数据逻辑的最终完成者，in our case当然就是计算各州的平均温度。最终结果如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/mapred_reduce.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;blockquote&gt;
      &lt;p&gt;6 总结&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Map/Reduce的并行执行过程：&lt;/p&gt;

&lt;p&gt;Mapper&amp;lt;K1，V1&amp;gt; ==》 &amp;lt;K2，V2&amp;gt;&lt;/p&gt;

&lt;p&gt;Reducer&amp;lt;K2，List&lt;V2&gt; &amp;gt;==》&amp;lt;K3，V3&amp;gt;&lt;/V2&gt;&lt;/p&gt;

&lt;p&gt;PS: You can find the java code for this example here:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/jsoftbiz/mapreduce_1&quot;&gt;https://github.com/jsoftbiz/mapreduce_1&lt;/a&gt;&lt;/p&gt;

&lt;h4 id=&quot;section&quot;&gt;实例演示&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;blockquote&gt;
      &lt;p&gt;1 演示WordCount&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;blockquote&gt;
      &lt;p&gt;2 演示上述平均温度统计&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;资源链接：&lt;a href=&quot;https://github.com/jsoftbiz/mapreduce_1&quot;&gt;https://github.com/jsoftbiz/mapreduce_1&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;需要使用到&lt;a href=&quot;http://hadoop.apache.org/docs/r2.6.4/hadoop-mapreduce-client/hadoop-mapreduce-client-core/HadoopStreaming.html&quot;&gt;streaming&lt;/a&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;` [hadoop@NN01 temperature]$ hadoop jar /home/hadoop/hadoop2.6/share/hadoop/tools/lib/*streaming*.jar -input /temperature/input/* -output /temperature/py-output -file mapper.py -mapper mapper.py -file reducer.py -reducer reducer.py 16/08/09 22:26:30 WARN streaming.StreamJob: -file option is deprecated, please use generic option -files instead. packageJobJar: [mapper.py, reducer.py, /tmp/hadoop-unjar8704173289988394156/] [] /tmp/streamjob6992547910816721479.jar tmpDir=null 16/08/09 22:26:32 INFO client.RMProxy: Connecting to ResourceManager at NN01.HadoopVM/192.168.71.128:8032 16/08/09 22:26:32 INFO client.RMProxy: Connecting to ResourceManager at NN01.HadoopVM/192.168.71.128:8032 16/08/09 22:26:33 INFO mapred.FileInputFormat: Total input paths to process : 1 16/08/09 22:26:33 INFO mapreduce.JobSubmitter: number of splits:2 16/08/09 22:26:33 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1470792183416_0002 16/08/09 22:26:34 INFO impl.YarnClientImpl: Submitted application application_1470792183416_0002 16/08/09 22:26:34 INFO mapreduce.Job: The url to track the job: http://NN01.HadoopVM:8088/proxy/application_1470792183416_0002/ 16/08/09 22:26:34 INFO mapreduce.Job: Running job: job_1470792183416_0002 16/08/09 22:26:47 INFO mapreduce.Job: Job job_1470792183416_0002 running in uber mode : false 16/08/09 22:26:47 INFO mapreduce.Job:  map 0% reduce 0% 16/08/09 22:26:57 INFO mapreduce.Job:  map 50% reduce 0% 16/08/09 22:26:58 INFO mapreduce.Job:  map 100% reduce 0% 16/08/09 22:27:06 INFO mapreduce.Job:  map 100% reduce 100% 16/08/09 22:27:06 INFO mapreduce.Job: Job job_1470792183416_0002 completed successfully 16/08/09 22:27:06 INFO mapreduce.Job: Counters: 49
File System Counters
	FILE: Number of bytes read=78
	FILE: Number of bytes written=330581
	FILE: Number of read operations=0
	FILE: Number of large read operations=0
	FILE: Number of write operations=0
	HDFS: Number of bytes read=407
	HDFS: Number of bytes written=18
	HDFS: Number of read operations=9
	HDFS: Number of large read operations=0
	HDFS: Number of write operations=2
Job Counters
	Launched map tasks=2
	Launched reduce tasks=1
	Data-local map tasks=2
	Total time spent by all maps in occupied slots (ms)=16690
	Total time spent by all reduces in occupied slots (ms)=6278
	Total time spent by all map tasks (ms)=16690
	Total time spent by all reduce tasks (ms)=6278
	Total vcore-milliseconds taken by all map tasks=16690
	Total vcore-milliseconds taken by all reduce tasks=6278
	Total megabyte-milliseconds taken by all map tasks=17090560
	Total megabyte-milliseconds taken by all reduce tasks=6428672
Map-Reduce Framework
	Map input records=9
	Map output records=9
	Map output bytes=54
	Map output materialized bytes=84
	Input split bytes=222
	Combine input records=0
	Combine output records=0
	Reduce input groups=3
	Reduce shuffle bytes=84
	Reduce input records=9
	Reduce output records=3
	Spilled Records=18
	Shuffled Maps =2
	Failed Shuffles=0
	Merged Map outputs=2
	GC time elapsed (ms)=2002
	CPU time spent (ms)=5260
	Physical memory (bytes) snapshot=685187072
	Virtual memory (bytes) snapshot=6260936704
	Total committed heap usage (bytes)=498597888
Shuffle Errors
	BAD_ID=0
	CONNECTION=0
	IO_ERROR=0
	WRONG_LENGTH=0
	WRONG_MAP=0
	WRONG_REDUCE=0
File Input Format Counters
	Bytes Read=185
File Output Format Counters
	Bytes Written=18 16/08/09 22:27:06 INFO streaming.StreamJob: Output directory: /temperature/py-output
·
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;blockquote&gt;
      &lt;p&gt;3 Writing an Hadoop MapReduce Program in Python&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;原文请参照：&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://www.michael-noll.com/tutorials/writing-an-hadoop-mapreduce-program-in-python/&quot;&gt;Writing an Hadoop MapReduce Program in Python&lt;/a&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;` [hadoop@NN01 hadoop]$ hadoop jar /home/hadoop/hadoop2.6/share/hadoop/tools/lib/*streaming*.jar -file /home/hadoop/words/mapper.py -mapper /home/hadoop/words/mapper.py -file /home/hadoop/words/reducer.py -reducer /home/hadoop/words/reducer.py -input /words/input/* -output /words/py-output 16/08/09 20:10:28 WARN streaming.StreamJob: -file option is deprecated, please use generic option -files instead. packageJobJar: [/home/hadoop/words/mapper.py, /home/hadoop/words/reducer.py, /tmp/hadoop-unjar5100483106189698643/] [] /tmp/streamjob6336434171947928949.jar tmpDir=null 16/08/09 20:10:29 INFO client.RMProxy: Connecting to ResourceManager at NN01.HadoopVM/192.168.71.128:8032 16/08/09 20:10:29 INFO client.RMProxy: Connecting to ResourceManager at NN01.HadoopVM/192.168.71.128:8032 16/08/09 20:10:30 INFO mapred.FileInputFormat: Total input paths to process : 2 16/08/09 20:10:30 INFO mapreduce.JobSubmitter: number of splits:2 16/08/09 20:10:31 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1470792183416_0001 16/08/09 20:10:32 INFO impl.YarnClientImpl: Submitted application application_1470792183416_0001 16/08/09 20:10:32 INFO mapreduce.Job: The url to track the job: http://NN01.HadoopVM:8088/proxy/application_1470792183416_0001/ 16/08/09 20:10:32 INFO mapreduce.Job: Running job: job_1470792183416_0001 16/08/09 20:10:45 INFO mapreduce.Job: Job job_1470792183416_0001 running in uber mode : false 16/08/09 20:10:45 INFO mapreduce.Job:  map 0% reduce 0% 16/08/09 20:10:59 INFO mapreduce.Job:  map 50% reduce 0% 16/08/09 20:11:03 INFO mapreduce.Job:  map 100% reduce 0% 16/08/09 20:11:05 INFO mapreduce.Job:  map 100% reduce 100% 16/08/09 20:11:06 INFO mapreduce.Job: Job job_1470792183416_0001 completed successfully 16/08/09 20:11:06 INFO mapreduce.Job: Counters: 49
File System Counters
	FILE: Number of bytes read=47
	FILE: Number of bytes written=330444
	FILE: Number of read operations=0
	FILE: Number of large read operations=0
	FILE: Number of write operations=0
	HDFS: Number of bytes read=223
	HDFS: Number of bytes written=25
	HDFS: Number of read operations=9
	HDFS: Number of large read operations=0
	HDFS: Number of write operations=2
Job Counters
	Launched map tasks=2
	Launched reduce tasks=1
	Data-local map tasks=2
	Total time spent by all maps in occupied slots (ms)=24400
	Total time spent by all reduces in occupied slots (ms)=3381
	Total time spent by all map tasks (ms)=24400
	Total time spent by all reduce tasks (ms)=3381
	Total vcore-milliseconds taken by all map tasks=24400
	Total vcore-milliseconds taken by all reduce tasks=3381
	Total megabyte-milliseconds taken by all map tasks=24985600
	Total megabyte-milliseconds taken by all reduce tasks=3462144
Map-Reduce Framework
	Map input records=2
	Map output records=4
	Map output bytes=33
	Map output materialized bytes=53
	Input split bytes=198
	Combine input records=0
	Combine output records=0
	Reduce input groups=3
	Reduce shuffle bytes=53
	Reduce input records=4
	Reduce output records=3
	Spilled Records=8
	Shuffled Maps =2
	Failed Shuffles=0
	Merged Map outputs=2
	GC time elapsed (ms)=1505
	CPU time spent (ms)=6830
	Physical memory (bytes) snapshot=677711872
	Virtual memory (bytes) snapshot=6261100544
	Total committed heap usage (bytes)=482869248
Shuffle Errors
	BAD_ID=0
	CONNECTION=0
	IO_ERROR=0
	WRONG_LENGTH=0
	WRONG_MAP=0
	WRONG_REDUCE=0
File Input Format Counters
	Bytes Read=25
File Output Format Counters
	Bytes Written=25 16/08/09 20:11:06 INFO streaming.StreamJob: Output directory: /words/py-output
`
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;hbase&quot;&gt;3 HBase&lt;/h3&gt;

&lt;h4 id=&quot;introduction-1&quot;&gt;Introduction&lt;/h4&gt;
&lt;p&gt;&lt;a href=&quot;http://hbase.apache.org/book.html#quickstart&quot;&gt;Apache Hbase&lt;/a&gt;安装及测试&lt;/p&gt;

&lt;p&gt;提供海量数据存储功能，是一种构建在HDFS之上的分布式、面向列的存储系统。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;blockquote&gt;
    &lt;p&gt;Browse to the Web UI&lt;/p&gt;
  &lt;/blockquote&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;connect to the UI for the Master&lt;a href=&quot;H1:16010&quot;&gt;H1:16010&lt;/a&gt; or &lt;a href=&quot;H2:16010&quot;&gt;H2:16010&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;the-apache-hbase-shell&quot;&gt;The Apache HBase Shell演示&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;1 &lt;a href=&quot;http://hbase.apache.org/book.html#scripting&quot;&gt;Scripting with Ruby&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;2 &lt;a href=&quot;http://hbase.apache.org/book.html#_running_the_shell_in_non_interactive_mode&quot;&gt;Running the Shell in Non-Interactive Mode&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;3 &lt;a href=&quot;http://hbase.apache.org/book.html#hbase.shell.noninteractive&quot;&gt;HBase Shell in OS Scripts&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;4 &lt;a href=&quot;http://hbase.apache.org/book.html#_read_hbase_shell_commands_from_a_command_file&quot;&gt;Read HBase Shell Commands from a Command File&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;data-modelhttphbaseapacheorgbookhtmldatamodel&quot;&gt;&lt;a href=&quot;http://hbase.apache.org/book.html#datamodel&quot;&gt;Data Model&lt;/a&gt;&lt;/h4&gt;

&lt;h2 id=&quot;service-programming&quot;&gt;2 Service Programming&lt;/h2&gt;

&lt;h3 id=&quot;zookeeper&quot;&gt;1 Zookeeper&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/images/zookeeper_small.gif&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://zookeeper.apache.org/&quot;&gt;Apache Zookeeper&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;kafka&quot;&gt;2 kafka&lt;/h3&gt;

&lt;p&gt;一个分布式的、分区的、多副本的实时消息发布和订阅系统。提供可扩展、高吞吐、低延迟、高可靠的消息分发服务。&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://kafka.apache.org/documentation.html#quickstart&quot;&gt;quickstart&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;视频教程&lt;a href=&quot;http://www.jikexueyuan.com/course/kafka/&quot;&gt;http://www.jikexueyuan.com/course/kafka/&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;blockquote&gt;
      &lt;p&gt;1 Introduction&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a href=&quot;http://kafka.apache.org/documentation.html#introduction&quot;&gt;Introduction&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;集群实现与演示&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;` [hadoop@NN01 ~]$ ~/tools/runRemoteCmd.sh &quot;/home/hadoop/kafka/bin/kafka-server-start.sh $KAFKA_HOME/config/server.properties &amp;amp;&quot; all
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;[hadoop@DN02 bin]$ $KAFKA_HOME/bin/kafka-console-producer.sh –broker-list NN01.HadoopVM:9092 –sync –topic test&lt;/p&gt;

&lt;p&gt;[hadoop@DN01 bin]$ $KAFKA_HOME/bin/kafka-console-consumer.sh –zookeeper NN01.HadoopVM:2181 –topic test –from-beginning
	`&lt;/p&gt;

&lt;h2 id=&quot;distributed-programming&quot;&gt;3 Distributed Programming&lt;/h2&gt;

&lt;h3 id=&quot;pig&quot;&gt;1 Pig&lt;/h3&gt;

&lt;h3 id=&quot;hive&quot;&gt;2 Hive&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/Hive/GettingStarted#GettingStarted-InstallationandConfiguration&quot;&gt;Hive Install&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://blog.csdn.net/reesun/article/details/8556078&quot;&gt;Hive metastore三种配置方式&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;建立在Hadoop基础上的开源的数据仓库，提供类似SQL的Hive QL语言操作结构化数据存储服务和基本的数据分析服务。&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/Hive/GettingStarted#GettingStarted-RunningHive&quot;&gt;Running Hive&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;spark&quot;&gt;3 Spark&lt;/h3&gt;

&lt;p&gt;基于内存进行计算的分布式计算框架。&lt;/p&gt;

&lt;h4 id=&quot;spark-overview&quot;&gt;Spark Overview&lt;/h4&gt;

&lt;p&gt;Apache Spark is a fast and general-purpose cluster computing system. It provides high-level APIs in Java, Scala, Python and R, and an optimized engine that supports general execution graphs. It also supports a rich set of higher-level tools including &lt;a href=&quot;http://spark.apache.org/docs/latest/sql-programming-guide.html&quot;&gt;Spark SQL&lt;/a&gt; for SQL and structured data processing, &lt;a href=&quot;http://spark.apache.org/docs/latest/ml-guide.html&quot;&gt;MLlib&lt;/a&gt; for machine learning, &lt;a href=&quot;http://spark.apache.org/docs/latest/graphx-programming-guide.html&quot;&gt;GraphX&lt;/a&gt; for graph processing, and &lt;a href=&quot;http://spark.apache.org/docs/latest/streaming-programming-guide.html&quot;&gt;Spark Streaming&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Spark的适用场景&lt;/p&gt;

&lt;p&gt;Spark是基于内存的迭代计算框架，适用于需要多次操作特定数据集的应用场合。需要反复操作的次数越多，所需读取的数据量越大，受益越大，数据量小但是计算密集度较大的场合，受益就相对较小
由于RDD的特性，Spark不适用那种异步细粒度更新状态的应用，例如web服务的存储或者是增量的web爬虫和索引。就是对于那种增量修改的应用模型不适合。
总的来说Spark的适用面比较广泛且比较通用。&lt;/p&gt;

&lt;p&gt;运行模式
本地模式
Standalone模式
Mesos模式
yarn模式&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;blockquote&gt;
      &lt;p&gt;1 Cluster Manager Types&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The system currently supports three cluster managers:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;blockquote&gt;
    &lt;p&gt;1 Standalone – a simple cluster manager included with Spark that makes it easy to set up a cluster.&lt;/p&gt;
  &lt;/blockquote&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;blockquote&gt;
    &lt;p&gt;2 Apache Mesos – a general cluster manager that can also run Hadoop MapReduce and service applications.&lt;/p&gt;
  &lt;/blockquote&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;blockquote&gt;
    &lt;p&gt;3 Hadoop YARN – the resource manager in Hadoop 2.&lt;/p&gt;
  &lt;/blockquote&gt;
&lt;/blockquote&gt;

&lt;h4 id=&quot;machine-learning-library-mllib-guidereferhttpsparkapacheorgdocslatestml-guidehtml&quot;&gt;Machine Learning Library (MLlib) Guide&lt;a href=&quot;http://spark.apache.org/docs/latest/ml-guide.html&quot;&gt;refer&lt;/a&gt;&lt;/h4&gt;

&lt;p&gt;&lt;a href=&quot;http://dblab.xmu.edu.cn/blog/spark-quick-start-guide/&quot;&gt;Spark快速入门指南 – Spark安装与基础使用&lt;/a&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;`
[hadoop@NN01 sparkapp]$ spark-submit --class &quot;SimpleApp&quot; ~/sparkapp/target/scala-2.11/simple-project_2.11-1.0.jar 2&amp;gt;&amp;amp;1|grep &quot;Line&quot; Lines with a: 4, Lines with b: 2
`
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h2 id=&quot;machine-learning&quot;&gt;4 Machine Learning&lt;/h2&gt;

&lt;h3 id=&quot;mahout&quot;&gt;1 Mahout&lt;/h3&gt;

&lt;h2 id=&quot;data-ingestion&quot;&gt;5 Data Ingestion&lt;/h2&gt;

&lt;h3 id=&quot;storm&quot;&gt;1 Storm&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;/images/storm-flow.png&quot; alt=&quot;&quot; /&gt;
&lt;a href=&quot;http://storm.apache.org/releases/1.0.1/Setting-up-a-Storm-cluster.html&quot;&gt;Setting up a Storm Cluster&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://www.oschina.net/translate/history-of-apache-storm-and-lessons-learned?cmp&amp;amp;p=4#&quot;&gt;Apache Storm 的历史及经验教训&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://storm.apache.org/releases/1.0.1/index.html&quot;&gt;Storm Index&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://storm.apache.org/talksAndVideos.html&quot;&gt;Talks and Slideshows&lt;/a&gt;&lt;/p&gt;

&lt;h4 id=&quot;section-1&quot;&gt;命名方式&lt;/h4&gt;

&lt;blockquote&gt;
  &lt;blockquote&gt;
    &lt;p&gt;Storm暴风雨：其组件大多也以气象名词命名&lt;/p&gt;

    &lt;p&gt;spout龙卷：形象的理解是把原始数据卷进Storm流式计算中&lt;/p&gt;

    &lt;p&gt;bolt雷电：从spout或者其他bolt中接收数据进行处理或者输出&lt;/p&gt;

    &lt;p&gt;nimbus雨云：主控节点，存在单点问题，不过可以用watchdog来保证其可用性，fast-fail后马上就启动&lt;/p&gt;

    &lt;p&gt;topology拓扑：Storm的任务单元，形象的理解拓扑的点是spout或者bolt，之间的数据流是线，整个构成一个拓扑&lt;/p&gt;
  &lt;/blockquote&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;sqoop&quot;&gt;2 Sqoop&lt;/h3&gt;

&lt;h2 id=&quot;system-deployment&quot;&gt;6 System Deployment&lt;/h2&gt;

&lt;h3 id=&quot;ambari&quot;&gt;1 Ambari&lt;/h3&gt;

</description>
        <pubDate>Thu, 04 Aug 2016 00:00:00 +0800</pubDate>
        <link>http://helloourworld.github.io/hadoop_family</link>
        <guid isPermaLink="true">http://helloourworld.github.io/hadoop_family</guid>
        
        
        <category>MLAdvance</category>
        
      </item>
    
  </channel>
</rss>
